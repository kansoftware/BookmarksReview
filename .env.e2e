# ===========================================
# Конфигурация LLM API для E2E тестирования
# ===========================================
# API-ключ для доступа к LLM провайдеру (тестовый)
LLM_API_KEY=test-api-key-for-e2e-testing

# Базовый URL API (используем mock-сервер)
LLM_BASE_URL=http://localhost:8888/v1

# Название модели для использования
LLM_MODEL=gpt-4o-mini

# Максимальное количество токенов в ответе
LLM_MAX_TOKENS=1000

# Температура генерации (0.0 - 1.0)
LLM_TEMPERATURE=0.7

# Количество запросов в минуту (rate limiting)
LLM_RATE_LIMIT=0

# ===========================================
# Конфигурация загрузки контента
# ===========================================
# Таймаут запроса в секундах
FETCH_TIMEOUT=5

# Максимальное количество параллельных запросов
FETCH_MAX_CONCURRENT=20

# Максимальный размер загружаемой страницы (МБ)
FETCH_MAX_SIZE_MB=5

# Количество попыток при ошибке
FETCH_RETRY_ATTEMPTS=1

# Задержка между попытками (секунды)
FETCH_RETRY_DELAY=0.1

# ===========================================
# Конфигурация вывода
# ===========================================
# Директория для сохранения результатов
OUTPUT_DIR=./e2e_test_output

# Включать ли метаданные в Markdown-файлы (true/false)
MARKDOWN_INCLUDE_METADATA=true

# Генерировать ли Mermaid-диаграмму структуры (true/false)
GENERATE_MERMAID_DIAGRAM=true

# ===========================================
# Конфигурация промпта
# ===========================================
# Путь к файлу с промптом для LLM
PROMPT_FILE=./prompts/summarize_prompt.txt

# ===========================================
# Конфигурация логирования
# ===========================================
# Уровень логирования (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Путь к файлу лога
LOG_FILE=./e2e_test.log