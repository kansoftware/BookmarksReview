# Утилита для экспорта и описания закладок браузера

## Описание
Консольная утилита на Python для автоматической обработки закладок из браузера Chrome. Утилита:
- Импортирует JSON-файл закладок Chrome
- Извлекает содержимое веб-страниц по сохраненным ссылкам
- Генерирует краткие описания страниц в Markdown формате с использованием OpenAI-совместимого API
- Создает Mermaid-диаграммы для визуализации структуры закладок
- Сохраняет результаты в файловую структуру, соответствующую иерархии исходных закладок

## Требования
- Python 3.9+
- Зависимости: см. `requirements.txt`

## Установка
```bash
pip install -r requirements.txt
```

## Настройка
Создайте файл `.env` на основе `.env.example` и укажите:
- `LLM_API_KEY` — API-ключ для LLM провайдера
- `LLM_BASE_URL` — URL API (например, OpenRouter)
- Другие параметры конфигурации

## Использование

### Базовый запуск
```bash
python -m src.main path/to/bookmarks.json
```

### Дополнительные опции
```bash
# Указать кастомный .env файл
python -m src.main bookmarks.json --config custom.env

# Изменить директорию вывода
python -m src.main bookmarks.json --output-dir ./my_export

# Возобновить прерванную обработку
python -m src.main bookmarks.json --resume

# Только парсинг без обработки контента
python -m src.main bookmarks.json --dry-run

# Подробное логирование
python -m src.main bookmarks.json --verbose

# Не генерировать Mermaid-диаграмму
python -m src.main bookmarks.json --no-diagram

# Ограничить количество параллельных запросов
python -m src.main bookmarks.json --max-concurrent 5
```

## Структура проекта
- `src/` — исходный код
  - `main.py` — основной workflow и CLI
  - `config.py` — управление конфигурацией
  - `models.py` — модели данных
  - `parser.py` — парсер JSON закладок
  - `fetcher.py` — загрузчик веб-контента
  - `summarizer.py` — генератор описаний
  - `diagram.py` — генератор Mermaid-диаграмм
  - `writer.py` — запись Markdown-файлов
  - `logger.py` — централизованная система логирования
  - `utils.py` — вспомогательные утилиты
- `prompts/` — файлы промптов
- `tests/` — тесты
- `.kilocode/` — документация проекта

## Особенности

### Асинхронная обработка
- Параллельная загрузка до 10 страниц одновременно
- Rate limiting для LLM API
- Graceful degradation при ошибках

### Управление прогрессом
- Сохранение прогресса в `progress.json`
- Возможность возобновления с `--resume`
- Checkpoint каждые 50 закладок

### Визуализация структуры
- Автоматическая генерация Mermaid-диаграмм
- Отображение иерархии папок и закладок
- Ограничение размера диаграммы для больших наборов

### Гибкая конфигурация
- Все параметры через .env файл
- Поддержка любого OpenAI-совместимого API
- Настраиваемые лимиты и таймауты

### Централизованное логирование
- Единая система логирования для всех модулей
- Настраиваемые уровни логирования (DEBUG, INFO, WARNING, ERROR, CRITICAL)
- Вывод в консоль и файл с ротацией
- Поддержка русского языка в сообщениях
- Удобные функции для логирования производительности и ошибок
- Структурированное форматирование логов

#### Уровни логирования
- **DEBUG**: Детальная отладочная информация (вызовы функций, внутренние состояния)
- **INFO**: Основные операции (загрузка, сохранение, обработка)
- **WARNING**: Не критичные проблемы (пропуск закладок, ограничения)
- **ERROR**: Ошибки обработки (неудачные запросы, ошибки записи)
- **CRITICAL**: Критические системные ошибки

#### Формат логов
```
YYYY-MM-DD HH:MM:SS - module_name - LEVEL - Сообщение на русском
```

#### Настройка логирования
```env
# Уровень логирования
LOG_LEVEL=INFO

# Путь к файлу лога
LOG_FILE=./bookmarks_export.log
```

#### Использование в коде
```python
from src.logger import get_logger, log_performance, log_error_with_context

logger = get_logger(__name__)
logger.info("Информационное сообщение")
log_performance("operation_name", duration, "детали")
log_error_with_context(error, {"context": "data"})
```